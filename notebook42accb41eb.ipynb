{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing the training data","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-29T07:41:21.168362Z","iopub.execute_input":"2021-11-29T07:41:21.168796Z","iopub.status.idle":"2021-11-29T07:41:21.178962Z","shell.execute_reply.started":"2021-11-29T07:41:21.168764Z","shell.execute_reply":"2021-11-29T07:41:21.177979Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"markdown","source":"I'm going to try to work with the training set. I will also try to validate my data based off the training set as well and make predictions based on the test set. ","metadata":{}},{"cell_type":"code","source":"training = pd.read_csv('/kaggle/input/titanic/train.csv')\ntest = pd.read_csv('/kaggle/input/titanic/test.csv')\n\ncombine= [training, test]\nall_data = pd.concat([training,test])\n\n%matplotlib inline \nall_data.columns","metadata":{"execution":{"iopub.status.busy":"2021-11-29T07:41:21.182101Z","iopub.execute_input":"2021-11-29T07:41:21.182605Z","iopub.status.idle":"2021-11-29T07:41:21.215645Z","shell.execute_reply.started":"2021-11-29T07:41:21.182555Z","shell.execute_reply":"2021-11-29T07:41:21.214612Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"training.info()","metadata":{"execution":{"iopub.status.busy":"2021-11-29T07:41:21.217710Z","iopub.execute_input":"2021-11-29T07:41:21.218051Z","iopub.status.idle":"2021-11-29T07:41:21.236266Z","shell.execute_reply.started":"2021-11-29T07:41:21.218005Z","shell.execute_reply":"2021-11-29T07:41:21.235141Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"training.describe()","metadata":{"execution":{"iopub.status.busy":"2021-11-29T07:41:21.238104Z","iopub.execute_input":"2021-11-29T07:41:21.239424Z","iopub.status.idle":"2021-11-29T07:41:21.279930Z","shell.execute_reply.started":"2021-11-29T07:41:21.239357Z","shell.execute_reply":"2021-11-29T07:41:21.279343Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"training.describe().columns","metadata":{"execution":{"iopub.status.busy":"2021-11-29T07:41:21.281820Z","iopub.execute_input":"2021-11-29T07:41:21.282752Z","iopub.status.idle":"2021-11-29T07:41:21.304798Z","shell.execute_reply.started":"2021-11-29T07:41:21.282718Z","shell.execute_reply":"2021-11-29T07:41:21.303947Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"markdown","source":"# Read a tip from Kaggle user \"KenJee\" that it's a good idea to seperate data into numerical variables and categorical variables to better understand the data","metadata":{}},{"cell_type":"code","source":"df_num = training[['Age', 'SibSp', 'Parch', 'Fare']]\ndf_cat = training[['Survived', 'Pclass', 'Sex', 'Ticket', 'Cabin', 'Embarked']]","metadata":{"execution":{"iopub.status.busy":"2021-11-29T07:41:21.306096Z","iopub.execute_input":"2021-11-29T07:41:21.306550Z","iopub.status.idle":"2021-11-29T07:41:21.313959Z","shell.execute_reply.started":"2021-11-29T07:41:21.306514Z","shell.execute_reply":"2021-11-29T07:41:21.312700Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"markdown","source":"### distributing the numberic variables and plotting them","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfor i in df_num.columns: \n    plt.hist(df_num[i])\n    plt.title(i)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-29T07:41:21.315405Z","iopub.execute_input":"2021-11-29T07:41:21.315752Z","iopub.status.idle":"2021-11-29T07:41:22.209260Z","shell.execute_reply.started":"2021-11-29T07:41:21.315721Z","shell.execute_reply":"2021-11-29T07:41:22.208167Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"markdown","source":"### We see that the age range distribution is normal but the rest is not really normal.","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\n\nprint(df_num.corr())\nsns.heatmap(df_num.corr())","metadata":{"execution":{"iopub.status.busy":"2021-11-29T07:41:22.210722Z","iopub.execute_input":"2021-11-29T07:41:22.211030Z","iopub.status.idle":"2021-11-29T07:41:22.502621Z","shell.execute_reply.started":"2021-11-29T07:41:22.210999Z","shell.execute_reply":"2021-11-29T07:41:22.501196Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"markdown","source":"### Above we can see the correlation between the different types of data, for example, age and siblings have a very LOW correlation","metadata":{}},{"cell_type":"code","source":"pd.pivot_table(training, index = 'Survived', values = ['Age', 'SibSp', 'Parch', 'Fare'])","metadata":{"execution":{"iopub.status.busy":"2021-11-29T07:41:22.504046Z","iopub.execute_input":"2021-11-29T07:41:22.505128Z","iopub.status.idle":"2021-11-29T07:41:22.532605Z","shell.execute_reply.started":"2021-11-29T07:41:22.505064Z","shell.execute_reply":"2021-11-29T07:41:22.531695Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"for i in df_cat.columns: \n    sns.barplot(df_cat[i].value_counts().index, df_cat[i].value_counts()).set_title(i)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-29T07:41:22.534478Z","iopub.execute_input":"2021-11-29T07:41:22.535043Z","iopub.status.idle":"2021-11-29T07:41:36.581246Z","shell.execute_reply.started":"2021-11-29T07:41:22.534998Z","shell.execute_reply":"2021-11-29T07:41:36.580118Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"markdown","source":"### Now let's do the same method but for the categorical data","metadata":{}},{"cell_type":"code","source":"print(pd.pivot_table(training, index = 'Survived', columns = 'Pclass', values = 'Ticket', aggfunc = 'count'))\nprint()\nprint(pd.pivot_table(training, index = 'Survived', columns = 'Sex', values = 'Ticket', aggfunc = 'count'))\nprint()\nprint(pd.pivot_table(training, index = 'Survived', columns = 'Embarked', values = 'Ticket', aggfunc = 'count'))\nprint()","metadata":{"execution":{"iopub.status.busy":"2021-11-29T07:41:36.582861Z","iopub.execute_input":"2021-11-29T07:41:36.583083Z","iopub.status.idle":"2021-11-29T07:41:36.627090Z","shell.execute_reply.started":"2021-11-29T07:41:36.583054Z","shell.execute_reply":"2021-11-29T07:41:36.625878Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"# check missing values in training data\ntraining.isnull().sum()\n","metadata":{"execution":{"iopub.status.busy":"2021-11-29T07:41:36.628836Z","iopub.execute_input":"2021-11-29T07:41:36.629182Z","iopub.status.idle":"2021-11-29T07:41:36.640967Z","shell.execute_reply.started":"2021-11-29T07:41:36.629137Z","shell.execute_reply":"2021-11-29T07:41:36.640010Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"markdown","source":"### It looks like we're missing a lot of data in age and cabin","metadata":{}},{"cell_type":"code","source":"# percent of missing \"Age\" \nprint('Percent of missing \"Age\" records is %.2f%%' %((training['Age'].isnull().sum()/training.shape[0])*100))","metadata":{"execution":{"iopub.status.busy":"2021-11-29T07:41:36.642649Z","iopub.execute_input":"2021-11-29T07:41:36.643142Z","iopub.status.idle":"2021-11-29T07:41:36.653714Z","shell.execute_reply.started":"2021-11-29T07:41:36.643109Z","shell.execute_reply":"2021-11-29T07:41:36.652543Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"# mean age\nprint('The mean of \"Age\" is %.2f' %(training[\"Age\"].mean(skipna=True)))\n# median age\nprint('The median of \"Age\" is %.2f' %(training[\"Age\"].median(skipna=True)))","metadata":{"execution":{"iopub.status.busy":"2021-11-29T07:41:36.657762Z","iopub.execute_input":"2021-11-29T07:41:36.659038Z","iopub.status.idle":"2021-11-29T07:41:36.666764Z","shell.execute_reply.started":"2021-11-29T07:41:36.658953Z","shell.execute_reply":"2021-11-29T07:41:36.665775Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"# percent of missing \"cabin\" \nprint('Percent of missing \"Cabin\" records is %.2f%%' %((training['Cabin'].isnull().sum()/training.shape[0])*100))","metadata":{"execution":{"iopub.status.busy":"2021-11-29T07:41:36.668349Z","iopub.execute_input":"2021-11-29T07:41:36.669068Z","iopub.status.idle":"2021-11-29T07:41:36.682937Z","shell.execute_reply.started":"2021-11-29T07:41:36.669005Z","shell.execute_reply":"2021-11-29T07:41:36.682011Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"markdown","source":"### I'm going to fill in the data that is missing. Code from YALDA JAFARI. She also went through the same problem I did","metadata":{}},{"cell_type":"code","source":"#deciding about age coloumn which have almost 19% missing datas.\n#Imputer age coloumn\nfrom sklearn.impute import SimpleImputer\n\n#train data             \nImp=SimpleImputer(strategy='median')\nnew_train=Imp.fit_transform(training.Age.values.reshape(-1,1))\ntraining['Age2'] = new_train\n\n#test data\nnew_test=Imp.fit_transform(test.Age.values.reshape(-1,1))\ntest['Age2'] = new_test\n\n\ntraining.drop('Age',axis=1,inplace=True)\ntest.drop('Age',axis=1,inplace=True)\n\n\ntraining.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-29T07:46:00.134130Z","iopub.execute_input":"2021-11-29T07:46:00.134562Z","iopub.status.idle":"2021-11-29T07:46:00.162393Z","shell.execute_reply.started":"2021-11-29T07:46:00.134525Z","shell.execute_reply":"2021-11-29T07:46:00.161674Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"training.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-11-29T07:47:59.573811Z","iopub.execute_input":"2021-11-29T07:47:59.574125Z","iopub.status.idle":"2021-11-29T07:47:59.584656Z","shell.execute_reply.started":"2021-11-29T07:47:59.574094Z","shell.execute_reply":"2021-11-29T07:47:59.584026Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"training[\"Embarked\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-11-29T07:50:16.546677Z","iopub.execute_input":"2021-11-29T07:50:16.547994Z","iopub.status.idle":"2021-11-29T07:50:16.557065Z","shell.execute_reply.started":"2021-11-29T07:50:16.547924Z","shell.execute_reply":"2021-11-29T07:50:16.556181Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"# filling in the missing null values with \"s\" for southampton\ntraining[\"Embarked\"].fillna(\"s\",inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T07:50:57.233724Z","iopub.execute_input":"2021-11-29T07:50:57.234229Z","iopub.status.idle":"2021-11-29T07:50:57.239609Z","shell.execute_reply.started":"2021-11-29T07:50:57.234177Z","shell.execute_reply":"2021-11-29T07:50:57.238569Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"code","source":"training.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-11-29T07:51:29.614960Z","iopub.execute_input":"2021-11-29T07:51:29.615301Z","iopub.status.idle":"2021-11-29T07:51:29.626448Z","shell.execute_reply.started":"2021-11-29T07:51:29.615251Z","shell.execute_reply":"2021-11-29T07:51:29.625347Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"markdown","source":"### Name feature","metadata":{}},{"cell_type":"code","source":"training[\"Name\"]","metadata":{"execution":{"iopub.status.busy":"2021-11-29T07:52:30.873723Z","iopub.execute_input":"2021-11-29T07:52:30.874007Z","iopub.status.idle":"2021-11-29T07:52:30.883636Z","shell.execute_reply.started":"2021-11-29T07:52:30.873976Z","shell.execute_reply":"2021-11-29T07:52:30.882741Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"markdown","source":"### Putting the names into an array","metadata":{}},{"cell_type":"code","source":"training['Title'] =training['Name'].apply(lambda x: x.split(', ')[1].split('. ')[0].strip())\ntest['Title'] =training['Name'].apply(lambda x: x.split(', ')[1].split('. ')[0].strip())\ntraining[\"Title\"].unique()","metadata":{"execution":{"iopub.status.busy":"2021-11-29T07:52:32.136366Z","iopub.execute_input":"2021-11-29T07:52:32.137347Z","iopub.status.idle":"2021-11-29T07:52:32.150725Z","shell.execute_reply.started":"2021-11-29T07:52:32.137261Z","shell.execute_reply":"2021-11-29T07:52:32.149676Z"},"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"code","source":"#Split the dataset to train and test\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=101)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T07:41:36.722318Z","iopub.status.idle":"2021-11-29T07:41:36.723338Z","shell.execute_reply.started":"2021-11-29T07:41:36.722979Z","shell.execute_reply":"2021-11-29T07:41:36.723022Z"},"trusted":true},"execution_count":null,"outputs":[]}]}